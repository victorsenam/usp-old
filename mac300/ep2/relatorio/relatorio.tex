%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Arsclassica Article
% LaTeX Template
% Version 1.1 (10/6/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Lorenzo Pantieri (http://www.lorenzopantieri.net) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
10pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
%twoside, % Two page layout (page indentation for binding and different headers)
headinclude,footinclude, % Extra spacing for the header and footer
BCOR5mm, % Binding correction
]{scrartcl}

\input{structure.tex} % Include the structure.tex file which specified the document structure and layout

\hyphenation{Fortran hy-phen-ation} % Specify custom hyphenation points in words with dashes where you would like hyphenation to occur, or alternatively, don't put any dashes in a word to stop hyphenation altogether

%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR(S)
%----------------------------------------------------------------------------------------

\title{\normalfont\spacedallcaps{Método dos Gradientes Conjugados}} % The article title
\subtitle{\normalfont\spacedallcaps{EP2 - MAC0300}}

\author{\spacedlowsmallcaps{Victor Sena Molero (8941317)}} % The article author(s) - author affiliations need to be specified in the AUTHOR AFFILIATIONS block

%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%	HEADERS
%----------------------------------------------------------------------------------------

\renewcommand{\sectionmark}[1]{\markright{\spacedlowsmallcaps{#1}}} % The header for all pages (oneside) or for even pages (twoside)
%\renewcommand{\subsectionmark}[1]{\markright{\thesubsection~#1}} % Uncomment when using the twoside option - this modifies the header on odd pages
\lehead{\mbox{\llap{\small\thepage\kern1em\color{halfgray} \vline}\color{halfgray}\hspace{0.5em}\rightmark\hfil}} % The header style

\pagestyle{scrheadings} % Enable the headers specified in this block

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS & LISTS OF FIGURES AND TABLES
%----------------------------------------------------------------------------------------

\maketitle % Print the title/author/date block

\setcounter{tocdepth}{2} % Set the depth of the table of contents to show sections and subsections only

\tableofcontents % Print the table of contents

%\listoffigures % Print the list of figures
%\listoftables % Print the list of tables

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\section*{Abstract} % This section will not appear in the table of contents due to the star (\section*)

Este é um relatório sobre a implementação do método dos Gradientes Conjugados para encontrar um $x \in \mathbb{R}^n$ tal que $Ax = b$ onde $A \in \mathbb{R}^{n \times n}$ é esparsa, positiva definida e conhecida e $b \in \mathbb{R}^n$ é conhecida.

%----------------------------------------------------------------------------------------

\newpage % Start the article content on the second page, remove this if you have a longer abstract that goes onto the second page

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\section{Introdução}
Durante o semestre foram estudadas várias formas de se resolver sistemas da forma $Ax = b$, é fácil perceber que, com hipóteses mais fortes, esse tipo de cálculo se torna mais fácil. Por exemplo, se $A$ for positiva definida, podemos aplicar a decomposição de Cholesky e evitar o cálculo da decomposição LU, que funciona, também, no caso onde $A$ é positiva definida. \\
O método dos Gradientes Conjugados tem, também, como hipótese, uma $A$ positiva definida. Porém, esse método permite que propriedades da matriz $A$, como, por exemplo, a esparsidade, sejam aproveitados. \\
O objetivo desse relatório é, então, explicitar o que foi entendido sobre o método em questão, mostrar uma forma de aproveitar a esparsidade da matriz no método dos Gradientes Conjugados e discutir a complexidade desse método, comparando o com a decomposição de Cholesky, já que esta é derivada das mesmas hipóteses que o método dos Gradientes conjugados. Além disso, pretendo explicar o que foi feito em outras partes do desenvolvimento, como, por exemplo, o método para gerar matrizes positivas definidas esparsas. \\
Para tentar entender o método, foram estudados dois textos, o livro \textit{Numerical Linear Algebra}\cite{trefethen1997numerical}, como indicado no enunciado do EP e um paper intitulado \textit{Painless Conjugate Gradient}\cite{shewchuk1994introduction}.
 
%----------------------------------------------------------------------------------------
%   GRADIENTES CONJUGADOS
%----------------------------------------------------------------------------------------

\section{Gradientes Conjugados}
O método dos Gradientes Conjugados, em \cite{shewchuk1994introduction} é apresentado como uma derivação dos métodos \textit{Steepest Descent} e \textit{Conjugate Directions}. Vou introduzir ambos brevemente aqui, para mostrar como eu entendi o método dos Gradientes Conjugados.

\subsection{Steepest Descent}
O método do \textit{Steepest Descent} busca encontrar o $x$ que tem a forma quadrática mínima com a matriz $A$ e o vetor $b$ dados no problema. \\
A forma quadrática de um vetor é uma função escalar e quadrática de um vetor da forma ~\cite[p.~2]{shewchuk1994introduction}
$$ f(x) = \frac{1}{2}x^{T}Ax - b^{T}x + c $$ 
E o gradiente da forma quadrática é simplesmente ~\cite[p.~3]{shewchuk1994introduction}
$$ f'(x) = Ax - b $$ 
Assim, é fácil ver que se $ f'(x) = 0 $ então
$$ Ax = b $$
resolvendo o problema. \\
Para uma $A$ positiva definida, é possível mostrar que só existe um mínimo para a forma quadrática ~\cite[p.~5]{shewchuk1994introduction} e não existe máximo, assim, calcular $f'(x) = 0$ é simplesmente minimizar a função $f(x)$ no seu único ponto de mínimo. Assim, seguir o gradiente maximiza a função, se seguirmos a direção oposta ao gradiente, estaremos nos aproximando cada vez mais do mínimo da função. E é nisso que o método se baseia. \\
Assim, o método chuta um ponto $x_0$ e, para calcular $x_{i+1}$, para todo $i$, vai na direção oposta à função $f'(x_i)$ o que garante que, com o tamanho certo do passo nessa direção, $\lim_{i \to \infty} f'(x_i) = 0$. \\
O problema é que este método pode dar passos na mesma direção que métodos anteriores, pois a direção dos passos é definida pelo gradiente de $f$. De fato, isso acontece na prática. O método de \textit{Conjugate Directions} impede que isso aconteça.

\subsection{Conjugate Directions}
Como dito acima, este método garante que nenhum as direções de cada passo sejam diferentes entre si. Para fazer isso, é introduzida a ideia de direção de busca. O método usa direções de busca $d_i$ diferentes entre si e sempre minimiza $f'(x_{i+1})$ com alterações do tipo $x_{i+1} = x_i + \alpha_i d_i$ para cada passo $i$. \\
Para isso, as direções geradas são \textit{A-ortogonais} entre si, ou seja, são tais que 
$$ \forall i,j \text{ t.q. } i \neq j\text{, } d_i^{T}Ad_j = 0 $$
Isso faz com que nenhum passo seja dado na mesma direção, já que elas são todas diferentes, e também faz com que as direções $d_0, d_1, \dots, d_i$ gerem um espaço vetorial de dimensão $i$, que chamaremos $\mathcal{D}_i$, como em \cite{shewchuk1994introduction}. Logo, se $x$ tem dimensão $n$, $x \in \mathcal{D}_n$. E já que $f'(x)$ é minimizado a cada iteração, $x_i$ é tal que $\forall p \in \mathcal{D}_i f(x_i) \leq f(p)$, ou seja, $x_i$ é o ponto mínimo de $f$ para o subespaço $\mathcal{D}_i$. \\
Agora falta conseguirmos $n$ direções de busca ${d_i}$ que são \textit{A-ortogonais} (ou seja, conjugadas) entre si. Para isso, o método de Conjugate Directions usa o processo de \textit{Gram-Schmidt} \cite[p.~25]{shewchuck1994introduction}. O problema é que, para aplicar esse método, todos os vetores já gerados devem ser guardados e percorridos completamente para gerar o próximo vetor, assim, naturalmente, o processo custa, em quantidade de operações $O(n^3)$ e $O(n^2)$ em espaço. \\

\subsection{O método dos Gradientes Conjugados}
Felizmente, existe uma maneira mais eficiente de gerar as direções de busca ${d_i}$. É isso que o método dos gradientes conjugados apresenta com os espaços de Krylov. 

% Caso A = I

%----------------------------------------------------------------------------------------
%   BIBLIOGRAFIA
%----------------------------------------------------------------------------------------

\bibliography{relatorio.bib} % The file containing the bibliography
\bibliographystyle{unsrt}
\renewcommand{\refname}{\spacedlowsmallcaps{Bibliografia}} % For modifying the bibliography heading

%----------------------------------------------------------------------------------------

\end{document}
